# InsightSwarm

**Multi-Agent AI Fact-Checking System**

Combat misinformation through adversarial debate. Four specialized AI agents work together to verify claims, check sources, and provide transparent reasoning.

---

## Project Status

**This project is currently under active development.**

Code and documentation will be added soon. Stay tuned for updates!

---

## What is InsightSwarm?

InsightSwarm is a multi-agent AI fact-checking system designed to combat misinformation through adversarial debate.

### Core Concept

Instead of relying on a single AI that can make mistakes or hallucinate sources, InsightSwarm uses **four specialized agents** that debate claims from different perspectives:

- **ProAgent** - Argues the claim is TRUE
- **ConAgent** - Argues the claim is FALSE  
- **FactChecker** - Verifies all cited sources
- **Moderator** - Synthesizes debate into final verdict

### Why This Matters

- 67% of internet users share content without verification
- 23% of AI responses contain hallucinated sources
- 900% increase in deepfakes in 2023

InsightSwarm addresses these problems with transparent, multi-perspective fact-checking.

---

## Planned Features

- Multi-agent adversarial debate system
- Anti-hallucination layer (source verification)
- Transparent reasoning (full debate transcripts)
- Real-time verification (under 60 seconds)
- Zero-cost infrastructure (free APIs)
- Web interface (Streamlit)
- REST API for integration
- Multilingual support (future)
- Mobile application (future)
- Image and video fact-checking (future)

---

## Getting Started

### Coming Soon

- Installation instructions
- Quick start guide
- Usage examples
- API documentation

**Watch this repository** to get notified when the code is released.

---

## Technical Stack

**Language:** Python 3.11+

**Frameworks:**
- Streamlit (Web UI)
- LangGraph (Agent Orchestration)

**LLM Backend:**
- Groq API (Llama 3.1 70B)
- Gemini 1.5 Flash (Backup)

**Database:**
- SQLite
- ChromaDB

**APIs:**
- Wikipedia API
- Brave Search API

---

## Academic Background

This project is developed as final year research at Bharat College of Engineering, affiliated to University of Mumbai.

**Research Foundation:**
- Multi-agent systems for misinformation detection (Zhang et al., 2023)
- Hallucination reduction in LLMs (Kumar & Singh, 2024)
- Adversarial debate for truth discovery (Chen et al., 2023)

---

## License

This project will be licensed under the MIT License.

---

## Acknowledgments

Built with LangGraph, Streamlit, and Groq API.

Free API providers: Groq, Google Gemini, Brave Search.

---

**Last Updated:** February 2025  
**Version:** 0.1.0 (Pre-release)